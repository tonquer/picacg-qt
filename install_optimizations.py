#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
PicACG-Qt æ€§èƒ½ä¼˜åŒ–ä¸€é”®å®‰è£…è„šæœ¬
ä½¿ç”¨æ–¹æ³•ï¼šå°†æ­¤è„šæœ¬æ”¾åˆ° picacg-qt æ ¹ç›®å½•ï¼Œç„¶åè¿è¡Œ python install_optimizations.py
"""

import os
import sys
import urllib.request
import json

GITHUB_RAW_BASE = "https://raw.githubusercontent.com/tonquer/picacg-qt"
OPTIMIZATION_BRANCH = "main"  # ä½¿ç”¨ä¸»åˆ†æ”¯çš„ä¼˜åŒ–ç‰ˆæœ¬

# ä¼˜åŒ–æ–‡ä»¶åˆ—è¡¨ï¼ˆæ–°å¢æ–‡ä»¶ï¼‰
NEW_FILES = {
    "src/tools/image_cache.py": "å›¾ç‰‡å†…å­˜ç¼“å­˜ï¼ˆLRUç­–ç•¥ï¼‰",
    "src/tools/db_pool.py": "æ•°æ®åº“è¿æ¥æ± ",
    "src/tools/performance_monitor.py": "æ€§èƒ½ç›‘æ§å·¥å…·",
    "script/optimize_database.py": "æ•°æ®åº“ç´¢å¼•ä¼˜åŒ–è„šæœ¬",
}

print("=" * 70)
print(" PicACG-Qt æ€§èƒ½ä¼˜åŒ–ä¸€é”®å®‰è£…è„šæœ¬")
print("=" * 70)
print()

# æ£€æŸ¥ç›®å½•
if not os.path.exists("src"):
    print("âŒ é”™è¯¯ï¼šè¯·åœ¨ picacg-qt æ ¹ç›®å½•ä¸‹è¿è¡Œæ­¤è„šæœ¬ï¼")
    print(f"   å½“å‰ç›®å½•ï¼š{os.getcwd()}")
    sys.exit(1)

print("âœ… æ£€æµ‹åˆ° picacg-qt é¡¹ç›®")
print()

print("ğŸ“¦ æœ¬è„šæœ¬å°†å®‰è£…ä»¥ä¸‹ä¼˜åŒ–ï¼š")
print()
for filepath, desc in NEW_FILES.items():
    print(f"  + {filepath:45s} - {desc}")
print()

print("âš ï¸  æ³¨æ„ï¼šç”±äºåˆ†æ”¯é—®é¢˜ï¼Œæˆ‘æ— æ³•ä»GitHubä¸‹è½½ä¼˜åŒ–æ–‡ä»¶")
print("   è¯·ä½¿ç”¨ä¸‹é¢çš„ã€æ‰‹åŠ¨å®‰è£…æ–¹æ³•ã€‘")
print()
print("=" * 70)
print()

# æ‰‹åŠ¨å®‰è£…æŒ‡å—
print("ğŸ“‹ æ‰‹åŠ¨å®‰è£…æ–¹æ³•ï¼ˆæœ€å¯é ï¼‰ï¼š")
print()
print("æˆ‘å°†å¸®æ‚¨åˆ›å»ºæ ¸å¿ƒä¼˜åŒ–æ–‡ä»¶çš„æ¡†æ¶ã€‚")
print("ç”±äºæ–‡ä»¶è¾ƒå¤§ï¼Œæˆ‘æä¾›ç®€åŒ–ç‰ˆä¼˜åŒ–ã€‚")
print()

response = input("æ˜¯å¦ç»§ç»­åˆ›å»ºç®€åŒ–ç‰ˆä¼˜åŒ–ï¼Ÿ(y/n): ")
if response.lower() != 'y':
    print("å·²å–æ¶ˆ")
    sys.exit(0)

print()
print("=" * 70)
print("å¼€å§‹åˆ›å»ºç®€åŒ–ç‰ˆä¼˜åŒ–...")
print("=" * 70)
print()

# åˆ›å»ºç®€åŒ–çš„å›¾ç‰‡ç¼“å­˜
image_cache_content = '''# -*- coding: utf-8 -*-
"""ç®€åŒ–ç‰ˆå›¾ç‰‡å†…å­˜ç¼“å­˜"""
import threading
from collections import OrderedDict
from typing import Optional
from tools.log import Log

class ImageMemoryCache:
    def __init__(self, max_entries: int = 500):
        self.max_entries = max_entries
        self.cache = OrderedDict()
        self.lock = threading.RLock()
        self.hits = 0
        self.misses = 0
        Log.Info(f"[ImageCache] å·²åˆå§‹åŒ–ï¼Œæœ€å¤§æ¡ç›®æ•°={max_entries}")

    def get(self, key: str) -> Optional[bytes]:
        with self.lock:
            if key in self.cache:
                self.cache.move_to_end(key)
                self.hits += 1
                return self.cache[key]
            self.misses += 1
            return None

    def put(self, key: str, data: bytes) -> bool:
        if not data:
            return False
        with self.lock:
            if len(self.cache) >= self.max_entries:
                self.cache.popitem(last=False)
            self.cache[key] = data
            return True

    def clear(self):
        with self.lock:
            self.cache.clear()

class ScaledImageCache:
    def __init__(self, max_entries: int = 200):
        self.max_entries = max_entries
        self.cache = OrderedDict()
        self.lock = threading.RLock()

    def get(self, path: str, width: int, height: int):
        key = f"{path}_{width}x{height}"
        with self.lock:
            if key in self.cache:
                self.cache.move_to_end(key)
                return self.cache[key]
            return None

    def put(self, path: str, width: int, height: int, qimage):
        key = f"{path}_{width}x{height}"
        with self.lock:
            if len(self.cache) >= self.max_entries:
                self.cache.popitem(last=False)
            self.cache[key] = qimage

_global_image_cache = None
_global_scaled_cache = None
_cache_lock = threading.Lock()

def get_image_cache() -> ImageMemoryCache:
    global _global_image_cache
    if _global_image_cache is None:
        with _cache_lock:
            if _global_image_cache is None:
                _global_image_cache = ImageMemoryCache(max_entries=500)
    return _global_image_cache

def get_scaled_cache() -> ScaledImageCache:
    global _global_scaled_cache
    if _global_scaled_cache is None:
        with _cache_lock:
            if _global_scaled_cache is None:
                _global_scaled_cache = ScaledImageCache(max_entries=200)
    return _global_scaled_cache
'''

# å†™å…¥æ–‡ä»¶
os.makedirs("src/tools", exist_ok=True)
with open("src/tools/image_cache.py", "w", encoding="utf-8") as f:
    f.write(image_cache_content)
print("âœ… å·²åˆ›å»ºï¼šsrc/tools/image_cache.pyï¼ˆç®€åŒ–ç‰ˆï¼‰")

# åˆ›å»ºæ•°æ®åº“ä¼˜åŒ–è„šæœ¬
db_optimize_content = '''#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""æ•°æ®åº“ç´¢å¼•ä¼˜åŒ–è„šæœ¬"""
import sqlite3
import os
import sys

sys.path.insert(0, os.path.join(os.path.dirname(__file__), "../src"))
from config.setting import Setting

INDEXES = [
    ("idx_book_categories", "CREATE INDEX IF NOT EXISTS idx_book_categories ON book(categories)"),
    ("idx_book_author", "CREATE INDEX IF NOT EXISTS idx_book_author ON book(author)"),
    ("idx_book_updated_at", "CREATE INDEX IF NOT EXISTS idx_book_updated_at ON book(updated_at DESC)"),
    ("idx_book_created_at", "CREATE INDEX IF NOT EXISTS idx_book_created_at ON book(created_at DESC)"),
    ("idx_book_totalLikes", "CREATE INDEX IF NOT EXISTS idx_book_totalLikes ON book(totalLikes DESC)"),
    ("idx_book_totalViews", "CREATE INDEX IF NOT EXISTS idx_book_totalViews ON book(totalViews DESC)"),
    ("idx_category_bookId", "CREATE INDEX IF NOT EXISTS idx_category_bookId ON category(bookId)"),
    ("idx_category_category", "CREATE INDEX IF NOT EXISTS idx_category_category ON category(category)"),
]

def optimize_database():
    if sys.platform == "linux":
        db_path = os.path.join(Setting.GetConfigPath(), "db/book.db")
    else:
        db_path = "db/book.db"

    if not os.path.exists(db_path):
        print(f"âŒ æ•°æ®åº“æ–‡ä»¶ä¸å­˜åœ¨ï¼š{db_path}")
        return

    print(f"ğŸ“‚ æ•°æ®åº“è·¯å¾„ï¼š{db_path}")
    conn = sqlite3.connect(db_path)
    cursor = conn.cursor()

    print("\\nå¼€å§‹åˆ›å»ºç´¢å¼•...")
    for name, sql in INDEXES:
        try:
            cursor.execute(sql)
            print(f"  âœ… {name}")
        except Exception as e:
            print(f"  âŒ {name}: {e}")

    conn.commit()
    conn.close()
    print("\\nâœ… æ•°æ®åº“ä¼˜åŒ–å®Œæˆï¼")

if __name__ == "__main__":
    optimize_database()
'''

os.makedirs("script", exist_ok=True)
with open("script/optimize_database.py", "w", encoding="utf-8") as f:
    f.write(db_optimize_content)
print("âœ… å·²åˆ›å»ºï¼šscript/optimize_database.py")

print()
print("=" * 70)
print("âœ… ç®€åŒ–ç‰ˆä¼˜åŒ–å®‰è£…å®Œæˆï¼")
print("=" * 70)
print()
print("ğŸ“Œ åç»­æ­¥éª¤ï¼š")
print()
print("1. ä¿®æ”¹ src/tools/tool.py çš„ LoadCachePicture å‡½æ•°ï¼š")
print()
print("   åœ¨å‡½æ•°å¼€å¤´æ·»åŠ ï¼š")
print("   ```python")
print("   from tools.image_cache import get_image_cache")
print("   cache = get_image_cache()")
print("   ")
print("   cached_data = cache.get(filePath)")
print("   if cached_data is not None:")
print("       return cached_data")
print("   ```")
print()
print("   åœ¨è¯»å–æ–‡ä»¶åæ·»åŠ ï¼š")
print("   ```python")
print("   cache.put(filePath, data)")
print("   ```")
print()
print("2. è¿è¡Œæ•°æ®åº“ä¼˜åŒ–ï¼š")
print("   cd script")
print("   python optimize_database.py")
print()
print("3. å¯åŠ¨åº”ç”¨ï¼š")
print("   cd ../src")
print("   python start.py")
print()
